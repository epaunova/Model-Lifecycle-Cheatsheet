## ðŸ§ª Evaluation

This section will showcase model evaluation best practices:

- Benchmarks: MMLU, ARC, TruthfulQA
- Prompt-based testing
- Auto-grading using GPT-4
- Human preference scoring (Elo / pairwise)

ðŸ”— See also: [LLM Eval Template](https://github.com/epaunova/llm-eval-template)
